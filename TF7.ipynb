{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring TF sub-metric a) and b), N=7\n",
    "\n",
    "# function: measure similarity submetric1 : lines removed then added\n",
    "def calculate_levenshtein_similarity_event1(hunk1,hunk2):\n",
    "    removed_lines_added = 0  \n",
    "    for idx, val in enumerate(hunk1):\n",
    "        for index, value in enumerate(hunk2):\n",
    "            if val.startswith('+++') == False and val.startswith('---') == False and value.startswith('+++') == False and value.startswith('---') == False:                   \n",
    "                if val.startswith('-') == True and value.startswith('+') == True:\n",
    "                    # measure the similarity between two strings\n",
    "                    sim = Levenshtein.ratio(val.lstrip('-'), value.lstrip('+'))\n",
    "                    if sim > 0.8:\n",
    "                        removed_lines_added = 1\n",
    "                        return removed_lines_added\n",
    "    return removed_lines_added\n",
    "\n",
    "\n",
    "# function: measure similarity submetric2 :  lines added then removed\n",
    "def calculate_levenshtein_similarity_event2(hunk1,hunk2):\n",
    "    added_lines_removed = 0 \n",
    "    for idx, val in enumerate(hunk1):\n",
    "        for index, value in enumerate(hunk2):\n",
    "            if val.startswith('+++') == False and val.startswith('---') == False and value.startswith('+++') == False and value.startswith('---') == False:\n",
    "                if val.startswith('+') == True and value.startswith('-') == True:\n",
    "                    sim = Levenshtein.ratio(val.lstrip('+'), value.lstrip('-'))\n",
    "                    if sim > 0.8:\n",
    "                        added_lines_removed = 1\n",
    "                        return added_lines_removed                    \n",
    "    return added_lines_removed\n",
    "\n",
    "\n",
    "# handle different hunk numbers\n",
    "def handle_multi_hunks(f_commit,s_commit,count_hunks_f,count_hunks_s):\n",
    "    removed_lines_added = 0\n",
    "    added_lines_removed = 0\n",
    "    \n",
    "    # 1.1 both files have only one modified code area/hunk\n",
    "    if len(count_hunks_f) == 1 and len(count_hunks_s) == 1:         \n",
    "        hunk_content_1 = f_commit[count_hunks_f[0]]\n",
    "        line_num_1 = re.split('[-,+,@@]',hunk_content_1)\n",
    "        star_line_1 = 0\n",
    "        if line_num_1[5].isdigit() and line_num_1[3].isdigit():\n",
    "            star_line_1 = int(line_num_1[5])\n",
    "            if (int(line_num_1[3]) < int(line_num_1[5])):\n",
    "                star_line_1 = int(line_num_1[3])\n",
    "            \n",
    "        a1 = int(line_num_1[3]) + int(line_num_1[4])\n",
    "        b1 = 0\n",
    "        if line_num_1[5].isdigit() and line_num_1[6].isdigit():\n",
    "            b1 = int(line_num_1[5]) + int(line_num_1[6])\n",
    "        end_line_1 = b1\n",
    "        if a1 > b1:\n",
    "            end_line_1 = a1\n",
    "            \n",
    "        hunk_content_2 = s_commit[count_hunks_s[0]]\n",
    "        line_num_2 = re.split('[-,+,@@]',hunk_content_2)\n",
    "        star_line_2 = 0\n",
    "        if line_num_2[3].isdigit() and line_num_2[5].isdigit():\n",
    "            star_line_2 = int(line_num_2[5])      \n",
    "            if (int(line_num_2[3]) < int(line_num_2[5])):\n",
    "                star_line_2 = int(line_num_2[3])\n",
    "                \n",
    "        a2 = int(line_num_2[3]) + int(line_num_2[4])\n",
    "        b2 = 0\n",
    "        if line_num_2[5].isdigit() and line_num_2[6].isdigit():\n",
    "            b2 = int(line_num_2[5]) + int(line_num_2[6])\n",
    "        end_line_2 = b2\n",
    "        if a2 > b2:\n",
    "            end_line_2 = a2\n",
    "             \n",
    "        if (int(star_line_2) <= int(star_line_1) < int(end_line_2)) or (int(star_line_2) < int(end_line_1) <= int(end_line_2)):\n",
    "            e= calculate_levenshtein_similarity_event1(f_commit,s_commit)\n",
    "            f = calculate_levenshtein_similarity_event2(f_commit,s_commit)\n",
    "            removed_lines_added = removed_lines_added + e\n",
    "            added_lines_removed = added_lines_removed + f \n",
    "\n",
    "            \n",
    "    # 1.2 one file has only one modified code area, another file has more than one modified code areas\n",
    "    if (len(count_hunks_f) == 1 or len(count_hunks_s) == 1) and (len(count_hunks_f) + len(count_hunks_s) > 2):\n",
    "        iter_hunk_list = []\n",
    "        target_hunk_list = []\n",
    "        target_commit_list = []\n",
    "        iter_commit_hunk_list = []\n",
    "        \n",
    "        if len(count_hunks_f) == 1:\n",
    "            iter_hunk_list = count_hunks_s\n",
    "            target_hunk_list = count_hunks_f\n",
    "            target_commit_list = f_commit\n",
    "            iter_commit_hunk_list = s_commit\n",
    "\n",
    "        if len(count_hunks_s) == 1:\n",
    "            iter_hunk_list = count_hunks_f\n",
    "            target_hunk_list = count_hunks_s\n",
    "            target_commit_list = s_commit\n",
    "            iter_commit_hunk_list = f_commit\n",
    "\n",
    "        target_hunk_content = target_commit_list[target_hunk_list[0]]\n",
    "        target_line_num = re.split('[-,+,@@]',target_hunk_content)\n",
    "        target_star_line = int(target_line_num[5])\n",
    "        \n",
    "        if (int(target_line_num[3]) < int(target_line_num[5])):\n",
    "            target_star_line = int(target_line_num[3])\n",
    "        a = int(target_line_num[3]) + int(target_line_num[4])\n",
    "        b = 0\n",
    "        if target_line_num[5].isdigit() and target_line_num[6].isdigit():\n",
    "            b = int(target_line_num[5]) + int(target_line_num[6])\n",
    "        target_end_line = b\n",
    "        if a > b:\n",
    "            target_end_line = a\n",
    "        # ['', '', '', '347', '7', '350', '21', '', 'defplot_grid(']\n",
    "        different_hunk_segment = []\n",
    "        for i in range(len(iter_hunk_list)):\n",
    "            cont_for_each_hunk = ''\n",
    "            if 0 <= i < len(iter_hunk_list)-1:\n",
    "                cont_for_each_hunk =  iter_commit_hunk_list[iter_hunk_list[i]:iter_hunk_list[i+1]]  \n",
    "            if i == len(iter_hunk_list)-1:\n",
    "                cont_for_each_hunk =  iter_commit_hunk_list[iter_hunk_list[i]:]\n",
    "            different_hunk_segment.append(cont_for_each_hunk)\n",
    "\n",
    "        # check if there is a same modified code area/hunk\n",
    "        for nn, each_hunk in enumerate(different_hunk_segment):\n",
    "            # each hunk header\n",
    "            cur_hunk_head = ''\n",
    "            for xx, each_line in enumerate(each_hunk):\n",
    "                if each_line.startswith('@@'):\n",
    "                    cur_hunk_head = each_line\n",
    "\n",
    "            iter_line_num = re.split('[-,+,@@]',cur_hunk_head)\n",
    "            cur_star_line = iter_line_num[5]\n",
    "            if (int(iter_line_num[3]) < int(iter_line_num[5])):\n",
    "                cur_star_line = int(target_line_num[3])\n",
    "            a = int(iter_line_num[3]) + int(iter_line_num[4])\n",
    "            b = int(iter_line_num[5]) + int(iter_line_num[6])\n",
    "            cur_end_line = b\n",
    "            if a > b:\n",
    "                cur_end_line = a\n",
    "            if (int(target_star_line) <= int(cur_star_line) < int(target_end_line)) or (int(target_star_line) < int(cur_end_line) <= int(target_end_line)):\n",
    "                # same area\n",
    "                if target_commit_list == f_commit:\n",
    "                    e = calculate_levenshtein_similarity_event1(target_commit_list,each_hunk)\n",
    "                    f = calculate_levenshtein_similarity_event2(target_commit_list,each_hunk)\n",
    "                    removed_lines_added = removed_lines_added + e\n",
    "                    added_lines_removed = added_lines_removed + f \n",
    "                else:\n",
    "                    e = calculate_levenshtein_similarity_event1(each_hunk,target_commit_list)\n",
    "                    f = calculate_levenshtein_similarity_event2(each_hunk,target_commit_list)\n",
    "                    removed_lines_added = removed_lines_added + e\n",
    "                    added_lines_removed = added_lines_removed + f \n",
    "\n",
    "                    \n",
    "    # 1.3 both two files have more than one modified code areas\n",
    "    if len(count_hunks_f) > 1 and len(count_hunks_s) > 1:\n",
    "        different_hunk_segment1 = []\n",
    "        different_hunk_segment2 = []\n",
    "        for i in range(len(count_hunks_f)):\n",
    "            # each hunk section\n",
    "            cont_for_each_hunk = ''\n",
    "            if 0 <= i < len(count_hunks_f)-1:\n",
    "                cont_for_each_hunk =  f_commit[count_hunks_f[i]:count_hunks_f[i+1]]  \n",
    "            if i == len(count_hunks_f)-1:\n",
    "                cont_for_each_hunk =  f_commit[count_hunks_f[i]:]\n",
    "            different_hunk_segment1.append(cont_for_each_hunk)\n",
    "            \n",
    "        for i in range(len(count_hunks_s)):\n",
    "            # each hunk section\n",
    "            cont_for_each_hunk = ''\n",
    "            if 0 <= i < len(count_hunks_s)-1:\n",
    "                cont_for_each_hunk = s_commit[count_hunks_s[i]:count_hunks_s[i+1]]  \n",
    "            if i == len(count_hunks_s)-1:\n",
    "                cont_for_each_hunk =  s_commit[count_hunks_s[i]:]\n",
    "            different_hunk_segment2.append(cont_for_each_hunk)\n",
    "\n",
    "        for aa, each_hunk1 in enumerate(different_hunk_segment1):\n",
    "            # each hunk header\n",
    "            cur_hunk_head1 = ''\n",
    "            for ee, each_line in enumerate(each_hunk1):\n",
    "                if each_line.startswith('@@'):\n",
    "                    cur_hunk_head1 = each_line\n",
    "\n",
    "            iter_line_num1 = re.split('[-,+,@@]',cur_hunk_head1)            \n",
    "            cur_star_line1 = -100\n",
    "            a1 = 0\n",
    "            b1 = 0\n",
    "            if len(iter_line_num1) >= 6 and iter_line_num1[5].isdigit():\n",
    "                if iter_line_num1[3].isdigit() and iter_line_num1[4].isdigit() and iter_line_num1[6].isdigit():\n",
    "                     \n",
    "                    cur_star_line1 = int(iter_line_num1[5])\n",
    "                    if (int(float(iter_line_num1[3])) < int(iter_line_num1[5])):\n",
    "                        cur_star_line1 = int(float(iter_line_num1[3]))\n",
    "\n",
    "                    a1 = int(float(iter_line_num1[3])) + int(iter_line_num1[4])      \n",
    "                    b1 = int(iter_line_num1[5]) + int(iter_line_num1[6])\n",
    "            else:\n",
    "                continue                \n",
    "            cur_end_line1 = b1            \n",
    "            if a1 > b1:\n",
    "                cur_end_line1 = a1\n",
    "\n",
    "            for bb, each_hunk2 in enumerate(different_hunk_segment2):\n",
    "                cur_hunk_head2 = ''\n",
    "                for cc, each_line in enumerate(each_hunk2):\n",
    "                    if each_line.startswith('@@'):\n",
    "                        cur_hunk_head2 = each_line\n",
    "                iter_line_num2 = re.split('[-,+,@@]',cur_hunk_head2)                \n",
    "                cur_star_line2 = 0\n",
    "                a2 = 0\n",
    "                b2 = 0\n",
    "                if len(iter_line_num2) >= 6 and iter_line_num2[5].isdigit():\n",
    "                    if iter_line_num2[3].isdigit() and iter_line_num2[4].isdigit() and iter_line_num2[6].isdigit():\n",
    "                        \n",
    "                        cur_star_line2 = iter_line_num2[5]                        \n",
    "                        if (int(iter_line_num2[3]) < int(iter_line_num2[5])):\n",
    "                            cur_star_line2 = int(iter_line_num2[3])                    \n",
    "                        a2 = int(iter_line_num2[3]) + int(iter_line_num2[4])\n",
    "                        b2 = int(iter_line_num2[5]) + int(iter_line_num2[6])\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                cur_end_line2 = b2\n",
    "                if a2 > b2:\n",
    "                    cur_end_line2 = a2\n",
    "                if (int(cur_star_line2) <= int(cur_star_line1) < int(cur_end_line2)) or (int(cur_star_line2) < int(cur_end_line1) <= int(cur_end_line2)):\n",
    "                    # same area\n",
    "                    e = calculate_levenshtein_similarity_event1(each_hunk1,each_hunk2)\n",
    "                    f = calculate_levenshtein_similarity_event2(each_hunk1,each_hunk2)\n",
    "                    removed_lines_added = removed_lines_added + e\n",
    "                    added_lines_removed = added_lines_removed + f                     \n",
    "    return removed_lines_added, added_lines_removed\n",
    "\n",
    "\n",
    "# function: compare seven successive commits: 1-2-3-4-5-6-7，2-3-4-5-6-7-8\n",
    "def compare_adjacent_commit_list(my_list,projectID):\n",
    "    c_removed_lines_added = 0\n",
    "    c_added_lines_removed = 0\n",
    "    count_hunks_f = []\n",
    "    count_hunks_s = []    \n",
    "    store_old_file_loc_plus = []\n",
    "    store_old_file_loc_minus = []    \n",
    "    store_new_file_loc_plus = []\n",
    "    store_new_file_loc_minus = []\n",
    "    \n",
    "    #Total_commit\n",
    "    n = len(my_list)  \n",
    "    window_size_commit_list = []\n",
    "    count =0\n",
    "    for i in range(len(my_list)-7):\n",
    "        window_size_commit_list = my_list[i:i+7]         \n",
    "        # [[1, 2], [1, 3],[1,4],[1,5],[1,6],[1,7]]\n",
    "        all_compare_pairs = []\n",
    "        every_compare_pair = []\n",
    "        for i in range(len(window_size_commit_list)):\n",
    "            if i+1 < len(window_size_commit_list):\n",
    "                every_compare_pair.append(window_size_commit_list[0])\n",
    "                every_compare_pair.append(window_size_commit_list[i+1])\n",
    "                all_compare_pairs.append(every_compare_pair)\n",
    "            every_compare_pair = []\n",
    "\n",
    "        for loc, each_commit_in_pair in enumerate(all_compare_pairs):\n",
    "            count += 1\n",
    "            count_hunks_f.clear()\n",
    "            count_hunks_s.clear()     \n",
    "            store_old_file_loc_plus.clear()\n",
    "            store_old_file_loc_minus.clear()\n",
    "            \n",
    "            store_new_file_loc_plus.clear()\n",
    "            store_new_file_loc_minus.clear()\n",
    "\n",
    "            for idx, val in enumerate(each_commit_in_pair[0]):\n",
    "                # @@\n",
    "                if val.startswith('@@') == True:\n",
    "                    count_hunks_f.append(idx)\n",
    "                #+++\n",
    "                if val.startswith('+++') == True:\n",
    "                    store_old_file_loc_plus.append(idx)\n",
    "                #---\n",
    "                if val.startswith('---') == True:\n",
    "                    store_old_file_loc_minus.append(idx)\n",
    "\n",
    "            for index, value in enumerate(each_commit_in_pair[1]):\n",
    "                # @@\n",
    "                if value.startswith('@@') == True:\n",
    "                    count_hunks_s.append(index)\n",
    "                #+++\n",
    "                if value.startswith('+++') == True:\n",
    "                    store_new_file_loc_plus.append(index)\n",
    "                #---\n",
    "                if value.startswith('---') == True:\n",
    "                    store_new_file_loc_minus.append(index)                     \n",
    "\n",
    "            c1 = 0\n",
    "            c2 = 0\n",
    "            # case 1:  both commits change only one file\n",
    "            if len(store_old_file_loc_plus) == 1 and len(store_new_file_loc_plus) == 1:\n",
    "                # changing the same file\n",
    "                old_version_file = (each_commit_in_pair[0][store_old_file_loc_plus[0]])\n",
    "                new_version_file = (each_commit_in_pair[1][store_new_file_loc_plus[0]])\n",
    "\n",
    "                if old_version_file == new_version_file:\n",
    "                    c1, c2 = handle_multi_hunks(each_commit_in_pair[0],each_commit_in_pair[1],count_hunks_f,count_hunks_s)\n",
    "\n",
    "\n",
    "            # case 2:  one commit changes only one file, another commit changes more than one files\n",
    "            if (len(store_old_file_loc_plus) == 1 or len(store_new_file_loc_plus) == 1) and (len(store_old_file_loc_plus) + len(store_new_file_loc_plus) > 2):\n",
    "                iter_file_list = []\n",
    "                target_file_list = []\n",
    "                target_commit_list = []\n",
    "                iter_commit_files_list = []\n",
    "\n",
    "                if len(store_old_file_loc_plus) == 1:\n",
    "                    iter_file_list = store_new_file_loc_plus\n",
    "                    target_file_list = store_old_file_loc_plus\n",
    "                    target_commit_list = each_commit_in_pair[0]\n",
    "                    iter_commit_files_list = each_commit_in_pair[1]\n",
    "\n",
    "                if len(store_new_file_loc_plus) == 1:\n",
    "                    iter_file_list = store_old_file_loc_plus\n",
    "                    target_file_list = store_new_file_loc_plus\n",
    "                    target_commit_list = each_commit_in_pair[1]\n",
    "                    iter_commit_files_list = each_commit_in_pair[0]\n",
    "\n",
    "                target_file_name = target_commit_list[target_file_list[0]]\n",
    "                all_iter_filenames = []\n",
    "                \n",
    "                # iterate the commit that contains multiple modified files and save different files into a list\n",
    "                different_file_segment = []\n",
    "                for i in range(len(iter_file_list)):\n",
    "                    all_iter_filenames.append(iter_commit_files_list[iter_file_list[i]])\n",
    "                    list_for_each_file = ''\n",
    "                    if 0 <= i < len(iter_file_list)-1:                        \n",
    "                        list_for_each_file =  iter_commit_files_list[iter_file_list[i]:iter_file_list[i+1]-1] \n",
    "                    if i == len(iter_file_list)-1:\n",
    "                        list_for_each_file =  iter_commit_files_list[iter_file_list[i]:]  \n",
    "\n",
    "                    different_file_segment.append(list_for_each_file)\n",
    "\n",
    "                # two commits had modifying a same file\n",
    "                if target_file_name in all_iter_filenames:\n",
    "                    for i, v in enumerate(different_file_segment):\n",
    "                        hunk_num_of_cur_file = []\n",
    "                        current_file_name = ''\n",
    "                        for jj, kk in enumerate(v):\n",
    "                            if kk.startswith('@@') == True:\n",
    "                                hunk_num_of_cur_file.append(jj)\n",
    "                            if kk.startswith('+++') == True:\n",
    "                                current_file_name = kk\n",
    "\n",
    "                        if target_file_name == current_file_name:\n",
    "                            if target_commit_list == each_commit_in_pair[0]:\n",
    "                                c1, c2 = handle_multi_hunks(each_commit_in_pair[0],v,count_hunks_f,hunk_num_of_cur_file)\n",
    "                            else:\n",
    "                                c1, c2 = handle_multi_hunks(v,each_commit_in_pair[1],hunk_num_of_cur_file,count_hunks_s)\n",
    "\n",
    "\n",
    "            # case 3: both commits had changed more than one files\n",
    "            if len(store_old_file_loc_plus) > 1 and len(store_new_file_loc_plus) > 1:\n",
    "                different_file_segment_c1 = []\n",
    "                different_file_segment_c2 = []\n",
    "                \n",
    "                for i in range(len(store_old_file_loc_plus)):\n",
    "                    if 0 <= i < len(store_old_file_loc_plus)-1:\n",
    "                        each_file_diff1 =  each_commit_in_pair[0][store_old_file_loc_plus[i]:store_old_file_loc_plus[i+1]-1]        \n",
    "                    if i == len(store_old_file_loc_plus)-1:\n",
    "                        each_file_diff1 =  each_commit_in_pair[0][store_old_file_loc_plus[i]:]        \n",
    "                    different_file_segment_c1.append(each_file_diff1)\n",
    "\n",
    "                for i in range(len(store_new_file_loc_plus)):\n",
    "                    if 0 <= i < len(store_new_file_loc_plus)-1:\n",
    "                        each_file_diff2 =  each_commit_in_pair[1][store_new_file_loc_plus[i]:store_new_file_loc_plus[i+1]-1]        \n",
    "                    if i == len(store_new_file_loc_plus)-1:\n",
    "                        each_file_diff2 =  each_commit_in_pair[1][store_new_file_loc_plus[i]:]        \n",
    "\n",
    "                    different_file_segment_c2.append(each_file_diff2)\n",
    "                list_1 = []\n",
    "                list_2 = []\n",
    "                for i, each_file1 in enumerate(different_file_segment_c1):\n",
    "                    hunk_num_of_cur_file1 = []         \n",
    "                    current_file1 = ''\n",
    "                    current_file2 = ''\n",
    "                    for n, e_line in enumerate(each_file1):\n",
    "                        if e_line.startswith('@@') == True:\n",
    "                            hunk_num_of_cur_file1.append(n)\n",
    "                        if e_line.startswith('+++') == True:\n",
    "                            current_file1 = e_line\n",
    "                            \n",
    "                    for a, each_file2 in enumerate(different_file_segment_c2):\n",
    "                        hunk_num_of_cur_file2 = []\n",
    "                        for j, e_line2 in enumerate(each_file2):\n",
    "                            if e_line2.startswith('@@') == True:\n",
    "                                hunk_num_of_cur_file2.append(j)\n",
    "                            if e_line2.startswith('+++') == True:\n",
    "                                current_file2 = e_line2\n",
    "                        x1 = 0\n",
    "                        x2 = 0\n",
    "                        if current_file1 == current_file2:\n",
    "                            x1, x2 = handle_multi_hunks(each_file1,each_file2,hunk_num_of_cur_file1,hunk_num_of_cur_file2)                     \n",
    "                            list_1.append(x1)\n",
    "                            list_2.append(x2)                \n",
    "                c1 = sum(list_1)\n",
    "                c2 = sum(list_2)\n",
    "            c_removed_lines_added = c_removed_lines_added + c1\n",
    "            c_added_lines_removed = c_added_lines_removed + c2\n",
    "                                  \n",
    "    print(projectID,' ',len(my_list),'            ',c_removed_lines_added,'               ',c_added_lines_removed)\n",
    "\n",
    "\n",
    "import re  \n",
    "import Levenshtein\n",
    "# match Date line\n",
    "p = \"(^Date:)(\\s*)(Mon|Thu|Tue|Wed|Fri|Sat|Sun)(.+)\" \n",
    "# the list storing the diff file name for each project, for example three projects below\n",
    "diff_list = ['4001','4008','4009']\n",
    "print('ID','TotalCommit','Case1_removed_then_added','Case2_added_then_removed')\n",
    "\n",
    "for gg, each_diff_file in enumerate(diff_list):    \n",
    "    diffs_file = path_to_diff_files + each_diff_file +'.txt'    \n",
    "    f = open(diffs_file,'r',encoding='utf-8',errors='ignore')\n",
    "    diffs_list = f.readlines() \n",
    "\n",
    "    # convert txt to [[C1],[C2],[]...]\n",
    "    store_date_line_index = []\n",
    "    for index, val in enumerate(diffs_list):       \n",
    "        if type(val) == bytes:    \n",
    "            val = val.decode(errors='ignore')\n",
    "        \n",
    "        match_date = re.match(p,val,flags=0) \n",
    "        if match_date != None: \n",
    "            store_date_line_index.append(index)\n",
    "\n",
    "    list_after_split = []\n",
    "    for i in range(len(store_date_line_index)):\n",
    "        sub_list_for_each_commit='C_'+str(i+1)\n",
    "        locals()['C_'+str(i+1)]=i \n",
    "        # the first commit\n",
    "        if i == 0:\n",
    "            sub_list_for_each_commit = diffs_list[:store_date_line_index[1]]\n",
    "        # the last commit\n",
    "        if i == (len(store_date_line_index)-1):\n",
    "            sub_list_for_each_commit = diffs_list[store_date_line_index[i]:] \n",
    "\n",
    "        if 0 < i < len(store_date_line_index)-1:\n",
    "            sub_list_for_each_commit =  diffs_list[store_date_line_index[i]:store_date_line_index[i+1]]\n",
    "        list_after_split.append(sub_list_for_each_commit) \n",
    "\n",
    "    compare_adjacent_commit_list(list_after_split,each_diff_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
