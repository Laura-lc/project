{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the english words that not in the corpus\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import os\n",
    "frequency_corpus = 'path_to_the_corpus'\n",
    "path = \"path_to_the_titlesAndBobies\"\n",
    "word_not_in_corpus = 'path/file_to_store_words_not_in_corpus'\n",
    "\n",
    "# for excluding the name entities\n",
    "p1 = '[A-Z]+([_][A-Z]+)+'\n",
    "p2 = '[a-z][a-z1-9]+([A-Z][a-z1-9]+)+'\n",
    "p3 = '[A-Z][a-z1-9]+([A-Z][a-z1-9]+)+'\n",
    "p4 = '[a-z]([A-Z][a-z]+)+'\n",
    "p5 = '[_][_]*(.+)'   \n",
    "p6 = '[a-z][_](.+)' \n",
    "p7 = '[_]([a-z]+[A-Z][a-z]+)+'\n",
    "\n",
    "fo = open(frequency_corpus,\"r\",encoding=\"utf-8\") \n",
    "word_data = json.load(fo)\n",
    "print('\\n word_data',type(word_data),len(word_data))\n",
    "\n",
    "f1 = open(word_not_in_corpus,\"w\",encoding=\"utf-8\")\n",
    "files= os.listdir(path)\n",
    "a = 0\n",
    "for file in files:\n",
    "    pro_id = file.split('.txt')[0]\n",
    "    pro_words_list = [] \n",
    "    if not os.path.isdir(file):\n",
    "        f2 = open(path + \"/\" + file,\"r\",encoding=\"utf-8\")\n",
    "        line = f2.readline()\n",
    "        while line:\n",
    "            each_comment_word_list = line.split()\n",
    "            pro_words_list.append(each_comment_word_list) \n",
    "            line = f2.readline()\n",
    "    \n",
    "    # record english words not in corpus\n",
    "    words_not_in_corpus = []\n",
    "    for cur_commit in pro_words_list:\n",
    "        for cur_word in cur_commit:            \n",
    "            v1 = re.match(p1,cur_word,flags=0)\n",
    "            v2 = re.match(p2,cur_word,flags=0)\n",
    "            v3 = re.match(p3,cur_word,flags=0)\n",
    "            v4 = re.match(p4,cur_word,flags=0)\n",
    "            v5 = re.match(p5,cur_word,flags=0)\n",
    "            v6 = re.match(p6,cur_word,flags=0)\n",
    "            v7 = re.match(p7,cur_word,flags=0)\n",
    "            # exclude the name entities\n",
    "            if \"()\" not in cur_word:\n",
    "                if v1 == None and v2 == None and v3 == None and v4 == None and v5 == None and v6 == None and v7 == None:\n",
    "                    cur_word = cur_word.strip(string.punctuation)\n",
    "                    cur_word = cur_word.lower()\n",
    "                    if cur_word not in word_data and len(cur_word) < 18:\n",
    "                        # e.g. top/bottom\n",
    "                        if '.' not in cur_word and '/' in cur_word and len(cur_word.split('/')) == 2 and cur_word.split('/')[0].encode( 'UTF-8' ).isalpha() == True and cur_word.split('/')[1].encode( 'UTF-8' ).isalpha() == True:\n",
    "                            words_not_in_corpus.append(cur_word)\n",
    "                        # if all alpha\n",
    "                        if cur_word.encode( 'UTF-8' ).isalpha() == True:\n",
    "                            words_not_in_corpus.append(cur_word)                \n",
    "    a += len(words_not_in_corpus)    \n",
    "    for i in words_not_in_corpus:\n",
    "        f1.write(i)\n",
    "        f1.write('\\n')\n",
    "print('total words',a)        \n",
    "fo.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicated english words that not in the corpus and sort it\n",
    "import json\n",
    "import string\n",
    "word_path = g + 'file_that_store_words_not_in_corpus'\n",
    "after_sort = g + 'path/file_to_store_the_sorted_words'  \n",
    " \n",
    "fo = open(word_path,\"r\",encoding=\"utf-8\")\n",
    "data = fo.readlines()\n",
    "print('total words',len(data))\n",
    "\n",
    "# remove the duplicated words\n",
    "unique_list = []\n",
    "for word in data:\n",
    "    word = word.replace('\\n','')\n",
    "    if word not in unique_list:\n",
    "        unique_list.append(word)           \n",
    "print('after remove duplicated',len(unique_list))\n",
    "\n",
    "# sorting\n",
    "f1 = open(after_sort,\"w\",encoding=\"utf-8\")\n",
    "sort_list = sorted(unique_list,key=str.lower)\n",
    "for i in sort_list:\n",
    "    f1.write(i)\n",
    "    f1.write('\\n')\n",
    "fo.close()\n",
    "f1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
