{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree classifier using sklearn module with entropy as splitting criterion\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "from IPython.display import Image\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# importing Dataset \n",
    "def importdata():\n",
    "    balance_data = pd.read_csv(your_file_path, sep= ',') \n",
    "    print (\"Dataset Length: \", len(balance_data)) \n",
    "    print (\"Dataset Shape: \", balance_data.shape) \n",
    "    print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data \n",
    "\n",
    "# Spliting the dataset into the training and testing dataset - in a ratio of 70:30 between training and testing \n",
    "# The “X ” set consists of predictor variables. The “Y” set consists of the outcome variable.\n",
    "# Using “.values” of numpy converting our dataframes into numpy arrays\n",
    "def splitdataset(balance_data):\n",
    "    X = balance_data.values[:, 2:10] \n",
    "    Y = balance_data.values[:, 0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "    return X, Y, X_train, X_test, y_train, y_test \n",
    "\n",
    "# Decision Trees - perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "    # max_depth: the max_depth parameter denotes maximum depth of the tree. \n",
    "\tclf_entropy = DecisionTreeClassifier(criterion = \"entropy\", random_state = 1, max_depth = 3, min_samples_leaf = 5)\n",
    "\tclf_entropy.fit(X_train, y_train) \n",
    "\treturn clf_entropy \n",
    "\n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object):\n",
    "\ty_pred = clf_object.predict(X_test) \n",
    "\tprint(\"Predicted values:\",len(y_pred),y_pred)\n",
    "\treturn y_pred \n",
    "    \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "    target_names = ['Rating 1','Rating 2','Rating 3']\n",
    "    print(\"Confusion Matrix of the classifier: \")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    # visually represent a confusion matrix\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax);\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['Rating 1','Rating 2','Rating 3']); ax.yaxis.set_ticklabels(['Rating 1', 'Rating 2','Rating 3']);    \n",
    "    print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100)\n",
    "    print(\"Report : \")\n",
    "    print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "       \n",
    "# Driver code \n",
    "def main():\n",
    "    # Building Phase \n",
    "    data = importdata() \n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
    "    \n",
    "    # Classifiers\n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
    "    \n",
    "    # Feature columns in your feature files\n",
    "    feature_cols = ['MergeComment', 'CommentLength', 'NumberofInstance', 'IncludeBugNumber','KeywordsList1','KeywordsList2','KeywordsList3','NumberofSpecialWords']\n",
    "\n",
    "    print(\"Prediction Results:\")\n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test, y_pred_entropy)\n",
    "    \n",
    "    # Decision tree classifier’s visualization\n",
    "    dot_data=tree.export_graphviz(clf_entropy,out_file=None,feature_names=feature_cols,class_names=['1','2','3'])\n",
    "    graph=pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_pdf('entropy-tree.pdf')\n",
    "                             \n",
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
