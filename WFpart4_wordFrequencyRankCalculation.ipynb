{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then calculae the average word frequency for commit title\n",
    "    #1) average WF for each comment\n",
    "    #2) average WF for each project    \n",
    "# Then calculae the average word frequency for commit title && Body\n",
    "    #1) average WF for each comment\n",
    "    #2) average WF for each project  \n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import os\n",
    "frequency_corpus = 'path_to_the_sorted_corpus'\n",
    "words_not_in_corpus = 'path/file_of_the_words_not_in_corpus_with_their_transformations'\n",
    "path = \"path_to_the_titles_or_titlesAndBodies\"\n",
    "\n",
    "# read the corpus words and frequency ranks into a dict\n",
    "corpus_dict = {}\n",
    "fo = open(frequency_corpus,\"r\",encoding=\"utf-8\") \n",
    "for line in fo.readlines():\n",
    "    line = line.strip()\n",
    "    if ':' in line:\n",
    "        k = line.split(':')[0].strip()\n",
    "        v = line.split(':')[2].strip()\n",
    "        corpus_dict[k] = v\n",
    "\n",
    "# read words not in corpus and it's transformation into a dict\n",
    "tranform_dict = {}\n",
    "f3 = open(words_not_in_corpus,\"r\",encoding=\"utf-8\")     \n",
    "for line in f3.readlines():\n",
    "    line = line.strip()\n",
    "    if ':' in line:\n",
    "        k = line.split(':')[0].strip()\n",
    "        v = line.split(':')[1].strip()\n",
    "        tranform_dict[k] = v\n",
    "    else:\n",
    "        tranform_dict[line.strip()] = '--'\n",
    "\n",
    "# For excluding the name extities\n",
    "p = '[(]?[#][0-9]+'\n",
    "p1 = '[A-Z]+([_][A-Z]+)+'\n",
    "p2 = '[a-z][a-z1-9]+([A-Z][a-z1-9]+)+'\n",
    "p3 = '[A-Z][a-z1-9]+([A-Z][a-z1-9]+)+' \n",
    "p4 = '[a-z]([A-Z][a-z]+)+' \n",
    "p5 = '[a-z1-9]+([_][a-z1-9]+)+' \n",
    "p6 = '[_][_]*(.+)'  \n",
    "p7 = '[a-z][_]([A-Z]*[a-z1-9]+)+' \n",
    "p8 = '[a-z][_](.+)'\n",
    "p9 = '[_]([a-z]+[A-Z][a-z]+)+'\n",
    "\n",
    "# read comment titles\n",
    "files= os.listdir(path)\n",
    "for file in files:\n",
    "    pro_id = file.split('.txt')[0]\n",
    "    pro_words_list = [] \n",
    "    if not os.path.isdir(file):\n",
    "        f2 = open(path + \"/\" + file,\"r\",encoding=\"utf-8\")\n",
    "        line = f2.readline()\n",
    "        while line:\n",
    "            each_comment_word_list = line.split()\n",
    "            pro_words_list.append(each_comment_word_list) \n",
    "            line = f2.readline()\n",
    "            \n",
    "    # 1. clean project word list \n",
    "    pro_word_list_clean = []\n",
    "    for idx,cur_comm_word_list in enumerate(pro_words_list):        \n",
    "        each_comm_w_list_clean = []           \n",
    "        # comment of current project\n",
    "        for index, val in enumerate(cur_comm_word_list):            \n",
    "            v = re.match(p,val,flags=0)\n",
    "            v1 = re.match(p1,val,flags=0)\n",
    "            v2 = re.match(p2,val,flags=0)\n",
    "            v3 = re.match(p3,val,flags=0)\n",
    "            v4 = re.match(p4,val,flags=0)\n",
    "            v5 = re.match(p5,val,flags=0)\n",
    "            v6 = re.match(p6,val,flags=0)\n",
    "            v7 = re.match(p7,val,flags=0)\n",
    "            v8 = re.match(p8,val,flags=0)\n",
    "            v9 = re.match(p9,val,flags=0)                        \n",
    "            # exluding name entities\n",
    "            if \"()\" not in val:\n",
    "                if v == None and v1 == None and v2 == None and v3 == None and v4 == None and v5 == None:\n",
    "                    if v6 == None and v7 == None and v8 == None and v9 == None:\n",
    "                        val = val.strip(string.punctuation)\n",
    "                        if '.' not in val and '(' not in val and ':' not in val and 'â†’' not in val:\n",
    "                            if len(val) > 0:\n",
    "                                each_comm_w_list_clean.append(val.lower())                                \n",
    "        pro_word_list_clean.append(each_comm_w_list_clean)   \n",
    "\n",
    "    # 2. check frequency rank\n",
    "    record_all_avg_commit_w_freq = []\n",
    "    for cur_comm in pro_word_list_clean:  \n",
    "        # record word frequency ranks for each commit\n",
    "        record_all_w_rank_of_a_commit = []         \n",
    "        for cur_word in cur_comm:\n",
    "            check_w_list = []           \n",
    "            # cur_word in words_not_in_corpus list, check tranformation\n",
    "            if cur_word in tranform_dict.keys():                \n",
    "                if tranform_dict[cur_word] != '--':\n",
    "                    # multiple words\n",
    "                    # handle missing space case: quickfix -> quick fix, \n",
    "                    # tranform_dict[cur_word] would be more than one word\n",
    "                    if ' ' in tranform_dict[cur_word]:\n",
    "                        check_w_list = tranform_dict[cur_word].split(' ')\n",
    "                        for d in check_w_list:\n",
    "                            if d in corpus_dict.keys():\n",
    "                                record_all_w_rank_of_a_commit.append(corpus_dict[d])\n",
    "\n",
    "                    # single word   \n",
    "                    elif tranform_dict[cur_word] in corpus_dict.keys():\n",
    "                        record_all_w_rank_of_a_commit.append(corpus_dict[tranform_dict[cur_word]])\n",
    "                        \n",
    "            elif cur_word in corpus_dict.keys():\n",
    "                record_all_w_rank_of_a_commit.append(corpus_dict[cur_word])\n",
    "        record_all_w_rank_of_a_commit = np.array(record_all_w_rank_of_a_commit).astype(np.float)\n",
    "\n",
    "        # average word freqency for each commit\n",
    "        cur_commit_avg_w_fre = np.mean(record_all_w_rank_of_a_commit)\n",
    "        record_all_avg_commit_w_freq.append(cur_commit_avg_w_fre)\n",
    "        \n",
    "    cur_project_avg_w_fre = np.nanmean(record_all_avg_commit_w_freq)\n",
    "    print(pro_id,cur_project_avg_w_fre)\n",
    "fo.close()\n",
    "f3.close()\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
